{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin Transformer\n",
    "自己制造一个 *Swin Transformer* ，当然最终的目的是想把它改造成 U-Net 的架构，我希望对它进行如下改进：\n",
    "1. 去除相对位置编码：我会在进行 qkv 映射的时候使用卷积，引入卷积的归纳偏置，看看是否可以去除相对位置编码问题\n",
    "2. 去除滑动窗口：因为使用了 U-Net 架构以及卷积，滑动窗口显得不是很必要\n",
    "\n",
    "> 暂时就想到了这些，之后有什么东西想到再加上去吧，也算锻炼一下自己的复现能力"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 预处理\n",
    "最基本的部分，包含 embedding，patch 划分，patch 还原，窗口划分，窗口复原"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 embedding\n",
    "对图像进行映射，准备转化为 Token 以便交给 Transformer 作处理\n",
    "可以选择是使用线性映射还是卷积，映射完之后自动转换成 Token 的 2d 表示，以便于之后的窗口划分\n",
    "1. embedding 并划分 patch\n",
    "\n",
    "> 后面思考了一下，既然要下采样，不如还是每一个像素当成一个 Token，256*256 也不是一个太大的分辨率，直接上吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "\n",
    "class patchEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "        进行 embedding 以及 patch 划分\n",
    "        Args:\n",
    "            inChannels: input image channels\n",
    "            embedDim: embedding dim\n",
    "            methods: how to do embedding, conv or linear\n",
    "        return:\n",
    "            x: (B,H,W,C), H & W is patch's height & width\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, emb_dim, methods):\n",
    "        super().__init__()\n",
    "        self.methods = methods\n",
    "        if methods == 'conv':\n",
    "            self.proj = nn.Conv2d(in_channels, emb_dim, 3, 1, 1)\n",
    "        elif methods == 'linear':\n",
    "            self.proj = nn.Linear(in_channels, emb_dim)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        if self.methods == 'conv':\n",
    "            x = self.proj(x)\n",
    "            x = rearrange(x, 'b c (h ph) (w pw) -> b h w (ph pw c)', ph=1, pw=1)\n",
    "        elif self.methods == 'linear':\n",
    "            x = rearrange(x, 'b c (h ph) (w pw) -> b h w (ph pw c)', ph=1, pw=1)\n",
    "            x = self.proj(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256, 16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "pe = patchEmbedding(3, 16, 'conv')\n",
    "test = torch.randn(1, 3, 256, 256)\n",
    "pe(test).shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 窗口划分\n",
    "将生成的 2d patch 进行窗口划分，以便于使用窗口自注意力\n",
    "1. 划分窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowPartition(x, window_size):\n",
    "    \"\"\"\n",
    "        Window partition, based on patch\n",
    "        Args:\n",
    "            windowSize: The size of the windos, based on patch\n",
    "        returns:\n",
    "            (B*numWindows, Wh, Ww, C), C is a Token\n",
    "    \"\"\"\n",
    "    x = rearrange(x, 'b (h wh) (w ww) c -> (b h w) wh ww c', wh=window_size, ww=window_size)   # B*numWindows windowHeight windowWidth C\n",
    "    return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 划分窗口还原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowReverse(x, window_size):\n",
    "    \"\"\"\n",
    "        Window reverse, reversing the window partition back to patch\n",
    "        Args:\n",
    "            imageSize: The size of the image, based on pixels\n",
    "        return:\n",
    "            (B, H, W, C)\n",
    "    \"\"\"\n",
    "    B, Wh, Ww, _ = x.shape\n",
    "    ratio = window_size//Wh\n",
    "    x = rearrange(x, '(b h w) wh ww c -> b (h wh) (w ww) c', h=ratio, w=ratio)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "test = torch.randn(1, 256, 256, 16)\n",
    "test_win = windowPartition(test, 8)\n",
    "test_rev = windowReverse(test_win, 256)\n",
    "test == test_rev\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型架构\n",
    "\n",
    "这里要开始编写模型的架构细节了，从每一个小结构来构成整个模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 窗口自注意力\n",
    "\n",
    "这里要编写窗口自注意力方法，swin transformer 在窗口自注意力中包含 mask 以及以及相对位置编码，这里打算不使用滑动窗口，但是会保留是否使用相对位置编码的选项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class windowAttention(nn.Module):\n",
    "    \"\"\"\n",
    "        Self attention based on windows\n",
    "        input: (B*num_windows, N, C)\n",
    "        Args:\n",
    "            patchSize: the size of the patch\n",
    "            patchDim: the dim of the patch, 2d representation\n",
    "            attentionDim: the projection dim of qkv\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size, dim, num_heads, pe_flag):\n",
    "        super().__init__()\n",
    "        self.to_qkv = nn.Conv2d(dim, dim*3, 3, 1, 1)\n",
    "        self.proj = nn.Conv2d(dim, dim, 3, 1, 1)\n",
    "        self.num_heads = num_heads\n",
    "        self.pe_Flag = pe_flag\n",
    "        self.window_size = window_size\n",
    "        head_dim = dim//num_heads\n",
    "        self.scale = head_dim**-0.5\n",
    "        if pe_flag:\n",
    "            # define a parameter table of relative position bias\n",
    "            self.relative_position_bias_table = nn.Parameter(\n",
    "                torch.zeros((2 * window_size - 1) * (2 * window_size - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "            # get pair-wise relative position index for each token inside the window\n",
    "            coords_h = torch.arange(self.window_size)\n",
    "            coords_w = torch.arange(self.window_size)\n",
    "            coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "            coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "            relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "            relative_coords[:, :, 0] += self.window_size - 1  # shift to start from 0\n",
    "            relative_coords[:, :, 1] += self.window_size - 1\n",
    "            relative_coords[:, :, 0] *= 2 * self.window_size - 1\n",
    "            relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "            self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape  # B*num_windows, window_size**2, C\n",
    "        x=rearrange(x,'b (wh ww) c -> b c wh ww',wh=self.window_size,ww=self.window_size)  # 转换为 2d 图像表示\n",
    "        qkv = self.to_qkv(x)    # B*num_windows, C**3, window_size, windowsize\n",
    "        qkv = rearrange(qkv, 'b (num head head_dim) wh ww  -> num b head (wh ww) head_dim',num=3, head=self.num_heads, head_dim=C//self.num_heads) # 转为 token 表示\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        q=q*self.scale\n",
    "        attn = (q @ k.transpose(-2,-1))\n",
    "\n",
    "        if self.pe_Flag:\n",
    "            relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "                self.window_size * self.window_size, self.window_size * self.window_size, -1)  # Wh*Ww,Wh*Ww,nH\n",
    "            relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "            attn = attn + relative_position_bias.unsqueeze(0)  # positional enbedding\n",
    "        \n",
    "        attn=self.softmax(attn)\n",
    "        x=(attn @ v) #B*num_windows, heads, n, head_dim\n",
    "        x=rearrange(x,'b head (wh ww) head_dim -> b (head head_dim) wh ww ',wh = self.window_size,ww=self.window_size)\n",
    "        x=self.proj(x)  # B*num_window, window_size, window_size, dim\n",
    "        x=rearrange(x,'b c wh ww -> b (wh ww) c')   # B*num_windows, n, c\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 16])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testWA = windowAttention(2,16,4,True)  # head=4,head_dim = 4\n",
    "test = torch.randn(1*4,2*2,16)  # 这里的数据符合窗口自注意力的数据，如果想要改变窗口的大小需要另行调整\n",
    "testWA(test).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 FeedForward\n",
    "这里要处理 FeedForward 结构，感觉有多种选择，一种是像传统的使用全连接层，或者是使用 CNN\n",
    "但是使用 CNN 也会有问题，是要在窗口内使用 CNN 还是在整张图像上使用 CNN\n",
    "\n",
    "> 其实我比较倾向在窗口内使用 CNN，因为既然划分了窗口，那么随着网络的加深降低图像的分辨率同样可以让不同窗口之间的信息进行交互\n",
    "> 但是如果想要实现全局自注意力还是需要让网络再深一层，不然就是随着网络的加深，窗口大小同时增大\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, method, dim, mlp_ratio):\n",
    "        \"\"\"\n",
    "            FeedForward Block\n",
    "            Args:\n",
    "                input: (B*num_winodw, N, C)\n",
    "                methods: the projection methods, cnn or mlp\n",
    "                dim: the dim of token\n",
    "                mlp_ratio: the dim of the hidden layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.method = method\n",
    "        if method == 'conv':\n",
    "            self.layer1 = nn.Conv2d(dim, dim*mlp_ratio, 3, 1, 1)\n",
    "            self.layer2 = nn.Conv2d(dim*mlp_ratio, dim, 3, 1, 1)\n",
    "        else:\n",
    "            self.layer1 = nn.Linear(dim, dim*mlp_ratio)\n",
    "            self.layer2 = nn.Linear(dim*mlp_ratio, dim)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.method == 'conv':\n",
    "            B, N, C = x.shape\n",
    "            wh = ww = int(N**0.5)\n",
    "            x = rearrange(x, 'b (wh ww) c -> b c wh ww',wh=wh,ww=ww)\n",
    "            x=self.layer1(x)\n",
    "            x=self.act(x)\n",
    "            x=self.layer2(x)\n",
    "            x = rearrange(x, 'b c wh ww -> b (wh ww) c')\n",
    "        else:\n",
    "            x=self.layer1(x)\n",
    "            x=self.act(x)\n",
    "            x=self.layer2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 16])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fw=FeedForward('linear',16,4)\n",
    "test_input=torch.randn(1*4,8*8,16)\n",
    "test_fw(test_input).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d75350062c91db8f31525500570c5ecc5362547a35f3bd097b0c9da2ada0503a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
